{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4cd10784",
   "metadata": {},
   "source": [
    "# 1. Download the Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7597d4",
   "metadata": {},
   "source": [
    "https://drive.google.com/file/d/1xkynpL15pt6KT3YSlDimu4A5iRU9qYck/view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a3acc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers,losses\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dropout,Input,Flatten,Dense,MaxPooling2D,Conv2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def99ff",
   "metadata": {},
   "source": [
    "# 2. Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "baab4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06cce7bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3457 images belonging to 5 classes.\n",
      "Found 860 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen= ImageDataGenerator(rescale=1./255, rotation_range=0.2,shear_range=0.2,\n",
    "    zoom_range=0.2,width_shift_range=0.2,\n",
    "    height_shift_range=0.2, validation_split=0.2)\n",
    "\n",
    "train_data= train_datagen.flow_from_directory(r'C:\\Users\\hp\\Downloads\\flowers',\n",
    "                                target_size=(80,80),batch_size=8,class_mode='categorical',subset='training' )\n",
    "\n",
    "validation_data= train_datagen.flow_from_directory(r'C:\\Users\\hp\\Downloads\\flowers',\n",
    "                                target_size=(80,80),batch_size=8,class_mode='categorical', subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fccfdfcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4317 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_data = test_datagen.flow_from_directory(r'C:\\Users\\hp\\Downloads\\flowers - test',\n",
    "                                target_size=(80,80),batch_size=8,class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b550d2",
   "metadata": {},
   "source": [
    "# 3. Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b136b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86367268",
   "metadata": {},
   "source": [
    "# 4. Add Layers (Convolution,MaxPooling,Flatten,Dense-(Hidden Layers),Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ec51f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(filters = 32, kernel_size = (5,5),activation ='relu', input_shape = (80,80,3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters = 64, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    " \n",
    "model.add(Conv2D(filters =96, kernel_size = (3,3),padding = 'Same',activation ='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512,activation='relu'))\n",
    "\n",
    "model.add(Dense(5, activation = \"softmax\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0694944",
   "metadata": {},
   "source": [
    "# 4. Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910707f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=losses.categorical_crossentropy,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2998d2f7",
   "metadata": {},
   "source": [
    "# 5. Fit The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "affa0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "433/433 [==============================] - 77s 175ms/step - loss: 1.3366 - accuracy: 0.4035 - val_loss: 1.2066 - val_accuracy: 0.5000\n",
      "Epoch 2/20\n",
      "433/433 [==============================] - 70s 163ms/step - loss: 1.1144 - accuracy: 0.5447 - val_loss: 0.9478 - val_accuracy: 0.6262\n",
      "Epoch 3/20\n",
      "433/433 [==============================] - 69s 160ms/step - loss: 0.9948 - accuracy: 0.6121 - val_loss: 0.8458 - val_accuracy: 0.6794\n",
      "Epoch 4/20\n",
      "433/433 [==============================] - 69s 160ms/step - loss: 0.9345 - accuracy: 0.6358 - val_loss: 0.8437 - val_accuracy: 0.6852\n",
      "Epoch 5/20\n",
      "433/433 [==============================] - 65s 150ms/step - loss: 0.8772 - accuracy: 0.6546 - val_loss: 0.9300 - val_accuracy: 0.6481\n",
      "Epoch 6/20\n",
      "433/433 [==============================] - 65s 150ms/step - loss: 0.8530 - accuracy: 0.6630 - val_loss: 0.7592 - val_accuracy: 0.7130\n",
      "Epoch 7/20\n",
      "433/433 [==============================] - 65s 149ms/step - loss: 0.8228 - accuracy: 0.6818 - val_loss: 0.7582 - val_accuracy: 0.7176\n",
      "Epoch 8/20\n",
      "433/433 [==============================] - 74s 170ms/step - loss: 0.7967 - accuracy: 0.6963 - val_loss: 0.6804 - val_accuracy: 0.7442\n",
      "Epoch 9/20\n",
      "433/433 [==============================] - 67s 154ms/step - loss: 0.7674 - accuracy: 0.7052 - val_loss: 0.7388 - val_accuracy: 0.6968\n",
      "Epoch 10/20\n",
      "433/433 [==============================] - 62s 144ms/step - loss: 0.7377 - accuracy: 0.7191 - val_loss: 0.6443 - val_accuracy: 0.7708\n",
      "Epoch 11/20\n",
      "433/433 [==============================] - 63s 145ms/step - loss: 0.7281 - accuracy: 0.7223 - val_loss: 0.6746 - val_accuracy: 0.7512\n",
      "Epoch 12/20\n",
      "433/433 [==============================] - 69s 160ms/step - loss: 0.7142 - accuracy: 0.7240 - val_loss: 0.6029 - val_accuracy: 0.7708\n",
      "Epoch 13/20\n",
      "433/433 [==============================] - 79s 183ms/step - loss: 0.6881 - accuracy: 0.7318 - val_loss: 0.5883 - val_accuracy: 0.7581\n",
      "Epoch 14/20\n",
      "433/433 [==============================] - 69s 159ms/step - loss: 0.6672 - accuracy: 0.7399 - val_loss: 0.5559 - val_accuracy: 0.7975\n",
      "Epoch 15/20\n",
      "433/433 [==============================] - 70s 161ms/step - loss: 0.6418 - accuracy: 0.7466 - val_loss: 0.6637 - val_accuracy: 0.7650\n",
      "Epoch 16/20\n",
      "433/433 [==============================] - 65s 149ms/step - loss: 0.6383 - accuracy: 0.7561 - val_loss: 0.5559 - val_accuracy: 0.8056\n",
      "Epoch 17/20\n",
      "433/433 [==============================] - 64s 148ms/step - loss: 0.6177 - accuracy: 0.7590 - val_loss: 0.5545 - val_accuracy: 0.7951\n",
      "Epoch 18/20\n",
      "433/433 [==============================] - 61s 142ms/step - loss: 0.6163 - accuracy: 0.7625 - val_loss: 0.5438 - val_accuracy: 0.8056\n",
      "Epoch 19/20\n",
      "433/433 [==============================] - 62s 143ms/step - loss: 0.5913 - accuracy: 0.7663 - val_loss: 0.4962 - val_accuracy: 0.8009\n",
      "Epoch 20/20\n",
      "433/433 [==============================] - 62s 142ms/step - loss: 0.5638 - accuracy: 0.7857 - val_loss: 0.5932 - val_accuracy: 0.7720\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_data,\n",
    "                   validation_data=test_data,\n",
    "                    epochs=20,validation_steps=len(validation_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db259491",
   "metadata": {},
   "source": [
    "# 6. Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e54bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'D:\\Processed Data\\Models\\Flower Prediction.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91784d1b",
   "metadata": {},
   "source": [
    "# 7. Test The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df17a6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=load_model(r'D:\\Processed Data\\Models\\Flower Prediction.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea7320d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img=image.load_img(r\"C:\\Users\\hp\\Downloads\\flowers\\sunflower\\44079668_34dfee3da1_n.jpg\",target_size=(80,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bd276c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pixels=image.img_to_array(test_img)\n",
    "pixels=np.expand_dims(pixels,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6329e125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 256ms/step\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(pixels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39882c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sunflower'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4d6978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
